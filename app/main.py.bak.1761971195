import sys
import datetime as dt
from fastapi.responses import HTMLResponse, RedirectResponse
import pytz
import logging
from fastapi.responses import RedirectResponse, HTMLResponse, RedirectResponse
from fastapi import Query, Request, Depends, Form
from fastapi import FastAPI, Query, Request, Form, Depends, Response
from fastapi.responses import JSONResponse, PlainTextResponse, RedirectResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from typing import Optional
from datetime import datetime
from app.config import load_config
from app.db import init_db, get_session, AutoCount, Controller, Season, Alert
from sqlalchemy import select, func
import os, json
group = 'min'

# Basic auth for settings
from fastapi.security import HTTPBasic, HTTPBasicCredentials
import secrets

security = HTTPBasic()

cfg = load_config()
init_db(cfg['db_path'])

app = FastAPI(title='LightShow Visitor Tracker')

def get_current_season(now_utc):
    s = get_session()
    q = s.query(Season).order_by(Season.start_date.desc())
    for season in q.all():
        if season.start_date <= now_utc < season.end_date:
            return season
    return None

app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

def await_correlate_like(sess, season, df, dt, camera):
    from app.db import FPPStatus
    q = select(AutoCount.timestamp, AutoCount.count_value, AutoCount.camera_name).where(AutoCount.count_type=='vehicle')
    if season: q = q.where(AutoCount.season==season)
    if df: q = q.where(AutoCount.timestamp >= df)
    if dt: q = q.where(AutoCount.timestamp < dt)
    if camera: q = q.where(AutoCount.camera_name==camera)
    q = q.order_by(AutoCount.timestamp.asc())
    rows = sess.execute(q).all()
    q2 = select(FPPStatus.timestamp, FPPStatus.media).order_by(FPPStatus.timestamp.asc())
    frows = sess.execute(q2).all()
    res = {}
    j=0
    for ts, cnt, camname in rows:
        while j+1 < len(frows) and frows[j+1][0] <= ts: j+=1
        media = frows[j][1] if frows else '(unknown)'
        if not media: media='(unknown)'
        res[media] = res.get(media,0) + int(cnt)
    return sorted(res.items(), key=lambda x:x[1], reverse=True)

ADMIN_USER = os.getenv("ADMIN_USERNAME", "admin")
ADMIN_PASS = os.getenv("ADMIN_PASSWORD", "changeme")

from fastapi import HTTPException  # make sure this import exists

def require_basic(request: Request):
    # Basic auth header parse
    auth = request.headers.get("Authorization", "")
    if not auth.startswith("Basic "):
        # Tell the browser to prompt for creds
        raise HTTPException(
            status_code=401,
            detail="Unauthorized",
            headers={"WWW-Authenticate": 'Basic realm="GlowSync"'}
        )

    import base64, os
    try:
        userpass = base64.b64decode(auth.split(" ", 1)[1]).decode("utf-8")
        username, password = userpass.split(":", 1)
    except Exception:
        raise HTTPException(
            status_code=401,
            detail="Bad auth header",
            headers={"WWW-Authenticate": 'Basic realm="GlowSync"'}
        )

    expected_user = os.getenv("ADMIN_USERNAME", "admin")
    expected_pass = os.getenv("ADMIN_PASSWORD", "changeme")
    if username != expected_user or password != expected_pass:
        raise HTTPException(
            status_code=401,
            detail="Invalid credentials",
            headers={"WWW-Authenticate": 'Basic realm="GlowSync"'}
        )

    # returning True satisfies FastAPI's Depends()
    return True
@app.get('/')
def root():
    return RedirectResponse('/dashboard')

@app.get('/health')
def health():
    return {'ok': True}

def _parse_time(s):
    if not s: return None
    try:
        return datetime.fromisoformat(s)
    except Exception:
        try:
            return datetime.fromisoformat(s + 'T00:00:00')
        except Exception:
            return None

@app.get('/counts')
def counts(type: str, 
           date_from: Optional[str] = Query(None),
           date_to: Optional[str] = Query(None)):
    df = _parse_time(date_from)
    dt = _parse_time(date_to)
    s = get_session()
    q = select(func.strftime('%Y-%m-%d %H:%M', AutoCount.timestamp).label('minute'),
               func.sum(AutoCount.count_value)).where(AutoCount.count_type==type)
    if df: q = q.where(AutoCount.timestamp >= df)
    if dt: q = q.where(AutoCount.timestamp < dt)
    q = q.group_by('minute').order_by('minute')
    rows = s.execute(q).all()
    return {'type': type, 'series': [{'minute': r[0], 'count': int(r[1])} for r in rows]}

@app.get('/dashboard_old', response_class=HTMLResponse)
def dashboard_old(
    request: Request,
    season: str = '',
    camera: str = '',
    date_from: Optional[str] = Query(None, alias='from'),
    date_to: Optional[str] = Query(None, alias='to'),
    corr: str = 'media'
):
    # Parse dates
    df = _parse_time(date_from)
    dt = _parse_time(date_to)

    # DB session FIRST so inner helpers can use it
    s = get_session()

    # Build series grouped by day/hour, with optional season/camera filters
    def series_for(ctype: str):
        fmt = '%Y-%m-%d' if group == 'day' else '%Y-%m-%d %H:00'
        q = select(
            func.strftime(fmt, AutoCount.timestamp).label('bucket'),
            func.sum(AutoCount.count_value)
        ).where(AutoCount.count_type == ctype)

        if season:
            q = q.where(AutoCount.season == season)
        if df:
            q = q.where(AutoCount.timestamp >= df)
        if dt:
            q = q.where(AutoCount.timestamp < dt)
        if camera and ctype == 'vehicle':
            q = q.where(AutoCount.camera_name == camera)

        q = q.group_by('bucket').order_by('bucket')
        rows = s.execute(q).all()
        labels = [r[0] for r in rows]
        values = [int(r[1]) for r in rows]
        total = sum(values) if values else 0
        peak_label, peak_count = ('—', 0)
        if values:
            idx = max(range(len(values)), key=lambda i: values[i])
            peak_label, peak_count = labels[idx], values[idx]
        return {'labels': labels, 'values': values, 'total': total, 'peak': {'label': peak_label, 'count': peak_count}}

    veh = series_for('vehicle')
    dev = series_for('device_seen')

    # Controllers badge & FPP info
    total = s.query(Controller).count()
    online = s.query(Controller).filter(Controller.last_status == 'online').count()
    fpp = s.query(Controller).filter(Controller.kind == 'fpp').order_by(Controller.id.asc()).first()
    fpp_info = {}
    if fpp and fpp.last_info_json:
        try:
            fpp_info = json.loads(fpp.last_info_json)
        except Exception:
            fpp_info = {}

    # Seasons list, cameras list, alerts
    seasons_list = s.query(Season).order_by(Season.start_date.desc()).all()
    cameras = [r[0] for r in s.execute(
        select(AutoCount.camera_name).where(AutoCount.camera_name != None).group_by(AutoCount.camera_name)
    ).all()]
    alerts = s.execute(
        select(Alert.timestamp, Alert.message).where(Alert.active == 1).order_by(Alert.timestamp.desc()).limit(5)
    ).all()

    # Top media (reuse correlation logic)
    def correlate_like(sess, season, df, dt, camera):
        from app.db import FPPStatus
        q = select(AutoCount.timestamp, AutoCount.count_value, AutoCount.camera_name).where(AutoCount.count_type == 'vehicle')
        if season: q = q.where(AutoCount.season == season)
        if df: q = q.where(AutoCount.timestamp >= df)
        if dt: q = q.where(AutoCount.timestamp < dt)
        if camera: q = q.where(AutoCount.camera_name == camera)
        q = q.order_by(AutoCount.timestamp.asc())
        rows = sess.execute(q).all()
        q2 = select(FPPStatus.timestamp, FPPStatus.media).order_by(FPPStatus.timestamp.asc())
        frows = sess.execute(q2).all()
        res = {}
        j = 0
        for ts, cnt, camname in rows:
            while j + 1 < len(frows) and frows[j + 1][0] <= ts:
                j += 1
            media = frows[j][1] if frows else '(unknown)'
            if not media: media = '(unknown)'
            res[media] = res.get(media, 0) + int(cnt)
        return sorted(res.items(), key=lambda x: x[1], reverse=True)

    top_media_pairs = correlate_like(s, season, df, dt, camera)[:10]
    top_media = [{'label': k, 'count': v} for k, v in top_media_pairs]

    return templates.TemplateResponse('dashboard.html', {
        'request': request,
        'title': 'Dashboard',
        'charts': {'vehicle': veh, 'device_seen': dev},
        'totals': {'vehicle': veh['total'], 'device_seen': dev['total']},
        'peaks': {'vehicle': veh['peak'], 'device_seen': dev['peak']},
        'controllers': {'online': online, 'total': total},
        'fpp': fpp_info,
        'seasons': seasons_list,
        'cameras': cameras,
        'top_media': top_media,
        'alerts': alerts,
        'params': {'from': date_from or '', 'to': date_to or '', 'group': group, 'season': season, 'camera': camera, 'corr': corr}
    })

@app.post('/ingest/autocount')
async def ingest_autocount(payload: dict):
    required = ['timestamp','source','count_type','count_value']
    if not all(k in payload for k in required):
        return JSONResponse({'error':'missing fields'}, status_code=400)
    from dateutil.parser import isoparse
    ts = isoparse(payload['timestamp'])
    s = get_session()
    rec = AutoCount(timestamp=ts, source=payload['source'],
                    camera_name=payload.get('camera_name'),
                    count_type=payload['count_type'],
                    count_value=int(payload['count_value']),
                    meta_json=payload.get('meta_json'))
    s.add(rec); s.commit()
    return {'ok': True, 'id': rec.id}

@app.get('/monitor', response_class=HTMLResponse)
def monitor_page(request: Request, auth: bool = Depends(require_basic)):
    s = get_session()
    controllers = s.query(Controller).order_by(Controller.name).all()
    return templates.TemplateResponse('monitor.html', {'request': request, 'controllers': controllers})

@app.post('/controllers/add')
def controllers_add(request: Request,
                    name: str = Form(...),
                    ip: str = Form(...),
                    kind: str = Form(...),
                    notes: str = Form(''),
                    auth: bool = Depends(require_basic)):
    s = get_session()
    c = Controller(name=name.strip(), ip=ip.strip(), kind=kind.strip(), notes=notes.strip())
    s.add(c); s.commit()
    return RedirectResponse('/monitor', status_code=303)

@app.get('/controllers/delete/{cid}')
def controllers_delete(cid: int, auth: bool = Depends(require_basic)):
    s = get_session()
    c = s.get(Controller, cid)
    if c:
        s.delete(c); s.commit()
    return RedirectResponse('/monitor', status_code=303)

from io import BytesIO
import xlsxwriter
from sqlalchemy import delete

@app.get('/seasons', response_class=HTMLResponse)
def seasons_page(request: Request, auth: bool = Depends(require_basic)):
    s = get_session()
    seasons = s.query(Season).order_by(Season.start_date.desc()).all()
    return templates.TemplateResponse('seasons.html', {'request': request, 'seasons': seasons})

@app.post('/seasons/add')
def seasons_add(name: str = Form(...),
                start: str = Form(...),
                end: str = Form(...),
                show_start: str = Form('17:00'),
                show_end: str = Form('23:00'),
                bucket: str = Form('1'),
                auth: bool = Depends(require_basic)):
    from dateutil.parser import isoparse
    tz = os.getenv('TIMEZONE','America/Chicago')
    # Store as UTC at midnight boundaries
    sd = isoparse(start + 'T00:00:00-06:00')  # rough CST; fine for coarse season bounds
    ed = isoparse(end + 'T00:00:00-06:00')
    s = get_session()
    season = Season(name=name.strip(), start_date=sd, end_date=ed,
                    show_start=show_start.strip(), show_end=show_end.strip(),
                    bucket_minutes=int(bucket))
    s.add(season); s.commit()
    return RedirectResponse('/seasons', status_code=303)

@app.get('/seasons/delete/{sid}')
def seasons_delete(sid: int, auth: bool = Depends(require_basic)):
    s = get_session()
    z = s.get(Season, sid)
    if z:
        s.delete(z); s.commit()
    return RedirectResponse('/seasons', status_code=303)

@app.get('/storage', response_class=HTMLResponse)
def storage_page(request: Request, auth: bool = Depends(require_basic)):
    s = get_session()
    seasons = s.query(Season).order_by(Season.start_date.desc()).all()
    dbp = os.getenv('DB_PATH','data/tracker.db')
    try:
        size_mb = round(os.path.getsize(dbp)/1048576, 2)
    except FileNotFoundError:
        size_mb = 0.0
    return templates.TemplateResponse('storage.html', {'request': request, 'seasons': seasons, 'db': {'path': dbp, 'size_mb': size_mb}})

@app.post('/purge')
def purge(before: str = Form(''), season_name: str = Form(''), auth: bool = Depends(require_basic)):
    s = get_session()
    from dateutil.parser import isoparse
    q = s.query(AutoCount)
    if season_name:
        q = q.filter(AutoCount.season==season_name)
    elif before:
        try:
            dt = isoparse(before + 'T00:00:00')
            q = q.filter(AutoCount.timestamp < dt)
        except Exception:
            return JSONResponse({'error':'bad date'}, status_code=400)
    else:
        return JSONResponse({'error':'no criteria'}, status_code=400)
    deleted = 0
    for row in q.all():
        s.delete(row); deleted += 1
    s.commit()
    # VACUUM
    s.execute('VACUUM')
    return RedirectResponse('/storage', status_code=303)

@app.get('/export.xlsx')
def export_xlsx(season: str, group: str = 'min', auth: bool = Depends(require_basic)):
    s = get_session()
    buf = BytesIO()
    wb = xlsxwriter.Workbook(buf, {'in_memory': True})
    ws = wb.add_worksheet('Summary')
    fmt_h = wb.add_format({'bold': True})
    ws.write_row(0,0, ['Season','GroupBy','Generated'], fmt_h)
    from datetime import datetime as _dt
    ws.write_row(1,0,[season, group, _dt.utcnow().isoformat()+'Z'])
    # Vehicles/devices sheets
    def write_sheet(ctype, name):
        ws2 = wb.add_worksheet(name)
        fmt = '%Y-%m-%d' if group=='day' else '%Y-%m-%d %H:00'
        q = select(func.strftime(fmt, AutoCount.timestamp).label('bucket'),
                   func.sum(AutoCount.count_value)).where(AutoCount.count_type==ctype, AutoCount.season==season).group_by('bucket').order_by('bucket')
        rows = s.execute(q).all()
        ws2.write_row(0,0,['bucket','count'], fmt_h)
        for i,(b,v) in enumerate(rows, start=1):
            ws2.write(i,0,b); ws2.write(i,1,int(v))
    write_sheet('vehicle','Vehicles')
    write_sheet('device_seen','Devices')
    wb.close()
    buf.seek(0)
    return Response(buf.read(), media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    headers={'Content-Disposition': f'attachment; filename="{season.replace(" ","_")}_export.xlsx"'})

@app.get('/correlate')
def correlate(group: str = 'min', season: str = '', date_from: Optional[str] = None, date_to: Optional[str] = None):
    # For each AutoCount bucket (vehicles), attach last-known FPPStatus at/before that timestamp, then group/sum.
    df = _parse_time(date_from)
    dt = _parse_time(date_to)
    s = get_session()
    # Build rows via Python (SQLite correlated subqueries are trickier without window functions)
    q = select(AutoCount.timestamp, AutoCount.count_value).where(AutoCount.count_type=='vehicle')
    if season:
        q = q.where(AutoCount.season==season)
    if df: q = q.where(AutoCount.timestamp >= df)
    if dt: q = q.where(AutoCount.timestamp < dt)
    q = q.order_by(AutoCount.timestamp.asc())
    rows = s.execute(q).all()
    # Preload FPP statuses
    from app.db import FPPStatus
    q2 = select(FPPStatus.timestamp, FPPStatus.playlist, FPPStatus.media).order_by(FPPStatus.timestamp.asc())
    frows = s.execute(q2).all()
    # Walk with pointer
    res = {}
    j = 0
    for ts, cnt in rows:
        while j+1 < len(frows) and frows[j+1][0] <= ts:
            j += 1
        label = None
        if frows:
            label = frows[j][1] if group=='playlist' else frows[j][2]
        if not label: label = '(unknown)'
        res[label] = res.get(label, 0) + int(cnt)
    # Return as sorted list
    ranked = sorted(([k,v] for k,v in res.items()), key=lambda x: x[1], reverse=True)
    return {'group': group, 'season': season, 'series': [{'label': k, 'count': v} for k,v in ranked]}

from app.util_env import set_env_vars

import re, pytz, os

@app.get('/settings', response_class=HTMLResponse)
def settings_get(request: Request, auth: bool = Depends(require_basic)):
    vals = {
        'timezone': os.getenv('TIMEZONE','America/Chicago'),
        'auto_refresh': os.getenv('DASHBOARD_AUTOREFRESH','60'),
        'baseline_mode': os.getenv('BALDRICK_BASELINE_MODE','manual'),
        'baseline': os.getenv('BALDRICK_BASELINE','0'),
        'baldrick_url': os.getenv('BALDRICK_CSV_URL',''),
        'admin_username': os.getenv('ADMIN_USERNAME','admin'),
    }
    tzs = pytz.common_timezones
    return templates.TemplateResponse('settings.html', {
        'request': request, 'saved': False, 'values': vals, 'timezones': tzs
    })

    updates = {
        'TIMEZONE': timezone,
        'DASHBOARD_AUTOREFRESH': max(int(auto_refresh), 0),
        'BALDRICK_BASELINE_MODE': baseline_mode,
        'BALDRICK_BASELINE': max(int(baseline), 0),
        'BALDRICK_CSV_URL': (baldrick_url or '').strip(),
        'ADMIN_USERNAME': admin_username,
    }
    if (admin_password or '').strip():
        updates['ADMIN_PASSWORD'] = admin_password.strip()

    logger.info('settings_post submit_action=%s', submit_action)
    set_env_vars(updates)

@app.post('/settings', response_class=HTMLResponse)
def settings_post(
    request: Request,
    timezone: str = Form(...),
    auto_refresh: int = Form(60),
    baseline_mode: str = Form('manual'),
    baseline: int = Form(0),
    baldrick_url: str = Form(''),
    admin_username: str = Form('admin'),
    admin_password: str = Form(''),
    auth: bool = Depends(require_basic)
):
    # Validate + normalize
    if timezone not in pytz.common_timezones:
        timezone = 'America/Chicago'
    if baseline_mode not in ('manual','auto'):
        baseline_mode = 'manual'
    admin_username = (admin_username or 'admin').strip()
    if not re.match(r'^[A-Za-z0-9_.-]{3,64}$', admin_username):
        admin_username = 'admin'

    updates = {
        'TIMEZONE': timezone,
        'DASHBOARD_AUTOREFRESH': max(int(auto_refresh), 0),
        'BALDRICK_BASELINE_MODE': baseline_mode,
        'BALDRICK_BASELINE': max(int(baseline), 0),
        'BALDRICK_CSV_URL': (baldrick_url or '').strip(),
        'ADMIN_USERNAME': admin_username,
    }
    if (admin_password or '').strip():
        updates['ADMIN_PASSWORD'] = admin_password.strip()

    # Persist settings
    set_env_vars(updates)

    # Defer restart via helper so response returns before services bounce
    import subprocess, os
    cmd = "sh -lc 'sleep 1; sudo /usr/local/sbin/glowsync-restart >/dev/null 2>&1 &'"
    try:
        subprocess.Popen(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, preexec_fn=os.setsid)
        return RedirectResponse(url="/settings?restarted=0", status_code=303)
    except Exception:
        return RedirectResponse(url="/settings?restarted=1", status_code=303)



def _default_window_minutes():
    try:
        return max(1, int(os.getenv('DEFAULT_WINDOW_MIN', '60')))
    except Exception:
        return 60

# --- GlowSync: clean /dashboard handler (last 60 minutes, per-minute) ---
import os, sqlite3, datetime as dt, pytz
from fastapi import Request, Depends
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates

if 'templates' not in globals():
    templates = Jinja2Templates(directory="templates")

def _gs_db_path() -> str:
    return os.path.expanduser("~/glowsync/data/tracker.db")

def _gs_last_window_utc(tzname: str, minutes: int = None):
    minutes = int(os.getenv('DEFAULT_WINDOW_MIN','60') or 60) if minutes is None else minutes
    tz = pytz.timezone(tzname or 'America/Chicago')
    now_local = dt.datetime.now(tz)
    start_local = now_local - dt.timedelta(minutes=minutes)
    return start_local.astimezone(dt.timezone.utc), now_local.astimezone(dt.timezone.utc), tz

@app.get('/dashboard', response_class=HTMLResponse)
def dashboard(request: Request, auth: bool = Depends(require_basic)):
    # Settings
    tzname = os.getenv('TIMEZONE','America/Chicago')
    baseline_mode = (os.getenv('BALDRICK_BASELINE_MODE','manual') or 'manual').lower()
    baseline_manual = int(os.getenv('BALDRICK_BASELINE','0') or 0)

    # Time window (last N minutes, default 60)
    df_utc, to_utc, _ = _gs_last_window_utc(tzname, minutes)
    df_iso, to_iso = df_utc.isoformat(), to_utc.isoformat()

    # Query DB
    dbp = _gs_db_path()
    con = sqlite3.connect(dbp)
    cur = con.cursor()
    # Ensure table exists (idempotent)
    cur.execute("""
      CREATE TABLE IF NOT EXISTS AutoCount (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        count_type   TEXT NOT NULL,
        source       TEXT NOT NULL,
        timestamp    TEXT NOT NULL,
        count_value  INTEGER NOT NULL,
        camera_name  TEXT,
        season       TEXT
      )
    """)

    # Auto baseline if requested: 10th percentile of last 7 days
    baseline = baseline_manual
    if baseline_mode == 'auto':
        start7 = (dt.datetime.now(dt.timezone.utc) - dt.timedelta(days=7)).isoformat()
        cur.execute("""
          SELECT count_value FROM AutoCount
          WHERE count_type='device_seen'
            AND source='baldrick'
            AND timestamp >= ?
          ORDER BY count_value ASC
        """, (start7,))
        vals = [r[0] for r in cur.fetchall()]
        if vals:
            idx = max(0, int(len(vals)*0.10)-1)
            baseline = int(vals[idx])

    # Pull last-window baldrick rows
    cur.execute("""
      SELECT timestamp, count_value
      FROM AutoCount
      WHERE count_type='device_seen'
        AND source='baldrick'
        AND timestamp >= ?
        AND timestamp <  ?
      ORDER BY timestamp ASC
    """, (df_iso, to_iso))
    rows = cur.fetchall()
    con.close()

    # Build series (Adjusted never below 0)
    labels, raw, adj = [], [], []
    for ts, v in rows:
        r = int(v)
        a = r - baseline
        if a < 0: a = 0
        # Convert UTC ISO -> local tz string (single line, readable)
        try:
            dt_utc = dt.datetime.fromisoformat(ts)
            if dt_utc.tzinfo is None:
                dt_utc = dt_utc.replace(tzinfo=dt.timezone.utc)
            dt_local = dt_utc.astimezone(tz)
            label = dt_local.strftime('%b %d · %I:%M %p').replace(' 0', ' ')
        except Exception:
            label = ts
        labels.append(label)
        raw.append(r)
        adj.append(a)
    peak_label = labels[adj.index(max(adj))] if adj else '—'
    peak_count = max(adj) if adj else 0

    return templates.TemplateResponse('dashboard.html', {
        'request': request,
        'title': 'Dashboard',
        'charts': {
            'device_seen': {
                'labels': labels,
                'raw_values': raw,
                'values': adj,
                'baseline_const': baseline
            }
        },
        'totals': {'device_seen': sum(adj)},
        'peaks': {'device_seen': {'label': peak_label, 'count': peak_count}},
        'params': {'group': 'min', 'tzname': tzname, 'win': (win or '1h'), 'win_label': win_label},
    })
# --- end clean /dashboard handler ---


@app.post('/admin/sync-baldrick')
def sync_baldrick(auth: bool = Depends(require_basic)):
    """Run the Baldrick CSV importer once, then bounce back to /dashboard."""
    try:
        script = (_Path.home() / "glowsync" / "scripts" / "sync_baldrick.py")
        subprocess.run([sys.executable, str(script)], check=False, timeout=90)
    except Exception:
        pass
    return RedirectResponse(url="/dashboard", status_code=303)


def _parse_window(win: str | None):
    presets = {
        '1h':60, '2h':120, '3h':180, '4h':240, '6h':360, '10h':600, '12h':720,
        '24h':1440, '48h':2880, '7d':10080, '30d':43200, 'week':10080, 'month':43200
    }
    if not win:
        return None, 'Last 60 min'
    w = win.strip().lower()
    if w in presets:
        return presets[w], f'Last {w}'
    try:
        mins = int(w)
        return max(mins, 1), f'Last {mins} min'
    except Exception:
        return None, 'Last 60 min'
